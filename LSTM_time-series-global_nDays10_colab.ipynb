{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSTM_time-series-global_nDays10.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "po2W6opNJMg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# This is not recommended but I am doing this to suppress warnings from SARIMAX\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "countryName = 'US'\n",
        "nFeatures = 1\n",
        "\n",
        "nDaysMin = 10\n",
        "\n",
        "nValid = 10\n",
        "nTest = 10\n",
        "\n",
        "dataDir = os.path.join('data', 'JHU', 'upto07082020_forPublication')\n",
        "\n",
        "\n",
        "# confirmedFilename = 'time_series_covid19_confirmed_global.csv'\n",
        "# deathsFilename = 'time_series_covid19_deaths_global.csv'\n",
        "# recoveredFilename = 'time_series_covid19_recovered_global.csv'\n",
        "\n",
        "confirmedFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_confirmed_global.csv'\n",
        "deathsFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_deaths_global.csv'\n",
        "recoveredFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_recovered_global.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LkWtyaDJMhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the sequence\n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LezNj9nFJMiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def meanAbsolutePercentageError(yTrueList, yPredList):\n",
        "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    absPcErrorList = [absError/yTrue for absError, yTrue in zip(absErrorList, yTrueList)]\n",
        "    MAPE = 100*np.mean(absPcErrorList)\n",
        "    return MAPE\n",
        "\n",
        "def meanForecastError(yTrueList, yPredList):\n",
        "    forecastErrors = [yTrue - yPred for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    MFE = np.mean(forecastErrors)\n",
        "    return MFE\n",
        "\n",
        "def meanAbsoluteError(yTrueList, yPredList):\n",
        "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    return np.mean(absErrorList)\n",
        "\n",
        "def meanSquaredError(yTrueList, yPredList):\n",
        "    sqErrorList = [np.square(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    return np.mean(sqErrorList)\n",
        "\n",
        "def rootMeanSquaredError(yTrueList, yPredList):\n",
        "    return np.sqrt(meanSquaredError(yTrueList, yPredList))\n",
        "\n",
        "def medianSymmetricAccuracy(yTrueList, yPredList):\n",
        "    '''https://helda.helsinki.fi//bitstream/handle/10138/312261/2017SW001669.pdf?sequence=1'''\n",
        "    logAccRatioList = [np.abs(np.log(yPred/yTrue)) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    MdSA = 100*(np.exp(np.median(logAccRatioList))-1)\n",
        "    return MdSA"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY-umeqIJMi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get all three frames for a given country\n",
        "def getCountryCovidFrDict(countryName):\n",
        "    countryCovidFrDict = {}\n",
        "    for key in covidFrDict.keys():\n",
        "        dataFr = covidFrDict[key]\n",
        "        countryCovidFrDict[key] = dataFr[dataFr['Country/Region'] == countryName]\n",
        "    return countryCovidFrDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydW9qOPgJMjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "98c753bf-135e-4604-ff22-cca6d85805a9"
      },
      "source": [
        "# Load all 3 csv files\n",
        "covidFrDict = {}\n",
        "# covidFrDict['confirmed'] = pd.read_csv(os.path.join(dataDir, confirmedFilename))\n",
        "# covidFrDict['deaths'] = pd.read_csv(os.path.join(dataDir, deathsFilename))\n",
        "covidFrDict['confirmed'] = pd.read_csv(confirmedFilename)\n",
        "covidFrDict['deaths'] = pd.read_csv(deathsFilename)\n",
        "\n",
        "# Recovered is back again!\n",
        "covidFrDict['recovered'] = pd.read_csv(recoveredFilename)\n",
        "\n",
        "countryCovidFrDict = getCountryCovidFrDict(countryName)\n",
        "\n",
        "# Get list of dates\n",
        "colNamesList = list(countryCovidFrDict['confirmed'])\n",
        "dateList = [colName for colName in colNamesList if '/20' in colName]\n",
        "dataList = [countryCovidFrDict['confirmed'][date].iloc[0] for date in dateList]\n",
        "dataDict = dict(zip(dateList, dataList))\n",
        "\n",
        "# Get time series for cases > 100 only\n",
        "daysSince = 100\n",
        "nCasesGreaterDaysSinceList = []\n",
        "datesGreaterDaysSinceList = []\n",
        "\n",
        "for key in dataDict.keys():\n",
        "    if dataDict[key] > daysSince:\n",
        "        datesGreaterDaysSinceList.append(key)\n",
        "        nCasesGreaterDaysSinceList.append(dataDict[key])\n",
        "        \n",
        "XList, yList = split_sequence(nCasesGreaterDaysSinceList, nDaysMin)\n",
        "\n",
        "XTrainList = XList[0:len(XList)-(nValid + nTest)]\n",
        "XValidList = XList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
        "XTestList = XList[-nTest:]\n",
        "\n",
        "yTrain = yList[0:len(XList)-(nValid + nTest)]\n",
        "yValid = yList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
        "yTest = yList[-nTest:]\n",
        "\n",
        "print('Total size of data points for LSTM:', len(yList))\n",
        "print('Size of training set:', len(yTrain))\n",
        "print('Size of validation set:', len(yValid))\n",
        "print('Size of test set:', len(yTest))\n",
        "\n",
        "# Convert from list to matrix\n",
        "XTrain = XTrainList.reshape((XTrainList.shape[0], XTrainList.shape[1], nFeatures))\n",
        "XValid = XValidList.reshape((XValidList.shape[0], XValidList.shape[1], nFeatures))\n",
        "XTest = XTestList.reshape((XTestList.shape[0], XTestList.shape[1], nFeatures))\n",
        "\n",
        "print(XTrain.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total size of data points for LSTM: 117\n",
            "Size of training set: 97\n",
            "Size of validation set: 10\n",
            "Size of test set: 10\n",
            "(97, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8snN9_XJMj0",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQCClpT5JMj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "d1bc5548-0bf1-45c3-9a20-76d3ba12d810"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "nNeurons = 100\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "    yPred = list(model.predict(XValid, verbose=0))\n",
        "    yPredList = []\n",
        "    for i in range(len(yPred)):\n",
        "        yPredList.append(yPred[i][0])\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "yPred = list(model.predict(XTest, verbose=0))\n",
        "yPredList = []\n",
        "for i in range(len(yPred)):\n",
        "    yPredList.append(yPred[i][0])\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "0 1.2694715030104144\n",
            "Updating best MAPE to 1.2694715030104144...\n",
            "Updating best seed to 0...\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9VGsoSJMkY",
        "colab_type": "text"
      },
      "source": [
        "# Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZB9pHOXJMkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(LSTM(nNeurons, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "    yPred = list(model.predict(XValid, verbose=0))\n",
        "    yPredList = []\n",
        "    for i in range(len(yPred)):\n",
        "        yPredList.append(yPred[i][0])\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(LSTM(nNeurons, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "yPred = list(model.predict(XTest, verbose=0))\n",
        "yPredList = []\n",
        "for i in range(len(yPred)):\n",
        "    yPredList.append(yPred[i][0])\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "101d6w9mJMk7",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CZ3DR9IJMk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "    yPred = list(model.predict(XValid, verbose=0))\n",
        "    yPredList = []\n",
        "    for i in range(len(yPred)):\n",
        "        yPredList.append(yPred[i][0])\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "yPred = list(model.predict(XTest, verbose=0))\n",
        "yPredList = []\n",
        "for i in range(len(yPred)):\n",
        "    yPredList.append(yPred[i][0])\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LItEpHSzJMle",
        "colab_type": "text"
      },
      "source": [
        "# CNN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD3fkWBAJMlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.compat.v1.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "# Number of subsequences to break X into (we do 10 = 5x2, 5 subsequences of size 2 each)\n",
        "nSeq = 5\n",
        "nSteps = 2\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "nFilters = 64\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "\n",
        "# Reshape input\n",
        "XTrainCNN = XTrainList.reshape((XTrainList.shape[0], nSeq, nSteps, nFeatures))\n",
        "XValidCNN = XValidList.reshape((XValidList.shape[0], nSeq, nSteps, nFeatures))\n",
        "XTestCNN = XTestList.reshape((XTestList.shape[0], nSeq, nSteps, nFeatures))\n",
        "\n",
        "# print(XTrainCNN.shape)\n",
        "# print(XValidCNN.shape)\n",
        "# print(XTestCNN.shape)\n",
        "\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
        "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(nNeurons, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrainCNN, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "    yPred = list(model.predict(XValidCNN, verbose=0))\n",
        "    yPredList = []\n",
        "    for i in range(len(yPred)):\n",
        "        yPredList.append(yPred[i][0])\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(nNeurons, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "# fit model\n",
        "model.fit(XTrainCNN, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "yPred = list(model.predict(XTestCNN, verbose=0))\n",
        "yPredList = []\n",
        "for i in range(len(yPred)):\n",
        "    yPredList.append(yPred[i][0])\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ1q6go3JMl8",
        "colab_type": "text"
      },
      "source": [
        "# ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiDLffINJMmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import ConvLSTM2D\n",
        "\n",
        "# Number of subsequences to break X into (we do 10 = 5x2, 5 subsequences of size 2 each)\n",
        "nSeq = 5\n",
        "nSteps = 2\n",
        "# Each input is rows x columns, we have rows=1 and columns=nSteps\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "nFilters = 64\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "\n",
        "# Reshape input\n",
        "XTrainConv = XTrainList.reshape((XTrainList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "XValidConv = XValidList.reshape((XValidList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "XTestConv = XTestList.reshape((XTestList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrainConv, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "    yPred = list(model.predict(XValidConv, verbose=0))\n",
        "    yPredList = []\n",
        "    for i in range(len(yPred)):\n",
        "        yPredList.append(yPred[i][0])\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "# fit model\n",
        "model.fit(XTrainConv, yTrain, epochs=1000, verbose=0)\n",
        "\n",
        "yPred = list(model.predict(XTestConv, verbose=0))\n",
        "yPredList = []\n",
        "for i in range(len(yPred)):\n",
        "    yPredList.append(yPred[i][0])\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}