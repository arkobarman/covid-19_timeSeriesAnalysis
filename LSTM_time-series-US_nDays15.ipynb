{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wA31NjwKPE7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.compat.v1.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "\n",
    "# This is not recommended but I am doing this to suppress warnings from SARIMAX\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "stateName = 'NY'\n",
    "nFeatures = 1\n",
    "\n",
    "nDaysMin = 15\n",
    "\n",
    "nValid = 10\n",
    "nTest = 10\n",
    "\n",
    "dataDir = os.path.join('data', 'covidtracking', 'upto07232020')\n",
    "# Read csv file\n",
    "USDataFilename = os.path.join(dataDir, 'daily.csv')\n",
    "USCovidFr = pd.read_csv(USDataFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUFQ3C_VKPF0"
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPonkwMtKPGR"
   },
   "outputs": [],
   "source": [
    "def meanAbsolutePercentageError(yTrueList, yPredList):\n",
    "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    absPcErrorList = [absError/yTrue for absError, yTrue in zip(absErrorList, yTrueList)]\n",
    "    MAPE = 100*np.mean(absPcErrorList)\n",
    "    return MAPE\n",
    "\n",
    "def meanForecastError(yTrueList, yPredList):\n",
    "    forecastErrors = [yTrue - yPred for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    MFE = np.mean(forecastErrors)\n",
    "    return MFE\n",
    "\n",
    "def meanAbsoluteError(yTrueList, yPredList):\n",
    "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    return np.mean(absErrorList)\n",
    "\n",
    "def meanSquaredError(yTrueList, yPredList):\n",
    "    sqErrorList = [np.square(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    return np.mean(sqErrorList)\n",
    "\n",
    "def rootMeanSquaredError(yTrueList, yPredList):\n",
    "    return np.sqrt(meanSquaredError(yTrueList, yPredList))\n",
    "\n",
    "def medianSymmetricAccuracy(yTrueList, yPredList):\n",
    "    '''https://helda.helsinki.fi//bitstream/handle/10138/312261/2017SW001669.pdf?sequence=1'''\n",
    "    logAccRatioList = [np.abs(np.log(yPred/yTrue)) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    MdSA = 100*(np.exp(np.median(logAccRatioList))-1)\n",
    "    return MdSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80BqzcooKPGr"
   },
   "outputs": [],
   "source": [
    "# Columns to use\n",
    "colsList = ['positive', 'negative', 'hospitalized', 'death']\n",
    "\n",
    "# Get dataframe for US State\n",
    "def getUSStateCovidFr(USStateName):\n",
    "    USStateCovidFr = USCovidFr[USCovidFr['state'] == USStateName]\n",
    "    return USStateCovidFr\n",
    "\n",
    "def convertDateToReadableFormat(dateList):\n",
    "    dtObjectList = []\n",
    "    for dateInt in dateList:\n",
    "        dateStr = str(dateInt)\n",
    "        x = datetime(int(dateStr[:4]), int(dateStr[4:6]), int(dateStr[6:8]))\n",
    "        dtObjectList.append(x)\n",
    "    dateTimeList = [dtObject.strftime('%m/%d/%y') for dtObject in dtObjectList]\n",
    "    return dateTimeList, dtObjectList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of data points for LSTM: 123\n",
      "Size of training set: 103\n",
      "Size of validation set: 10\n",
      "Size of test set: 10\n",
      "(103, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "USStateCovidFr = getUSStateCovidFr(stateName)\n",
    "dateList = USStateCovidFr['date'].tolist()\n",
    "readableDateList, _ = convertDateToReadableFormat(dateList)\n",
    "dataList = USStateCovidFr['positive'].tolist()\n",
    "dataDict = dict(zip(dateList, dataList))\n",
    "\n",
    "# Get time series for cases > 100 only\n",
    "daysSince = 100\n",
    "nCasesGreaterDaysSinceList = []\n",
    "datesGreaterDaysSinceList = []\n",
    "\n",
    "for key in dataDict.keys():\n",
    "    if dataDict[key] > daysSince:\n",
    "        datesGreaterDaysSinceList.append(key)\n",
    "        nCasesGreaterDaysSinceList.append(dataDict[key])\n",
    "        \n",
    "XList, yList = split_sequence(nCasesGreaterDaysSinceList, nDaysMin)\n",
    "\n",
    "XTrainList = XList[0:len(XList)-(nValid + nTest)]\n",
    "XValidList = XList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
    "XTestList = XList[-nTest:]\n",
    "\n",
    "yTrain = yList[0:len(XList)-(nValid + nTest)]\n",
    "yValid = yList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
    "yTest = yList[-nTest:]\n",
    "\n",
    "print('Total size of data points for LSTM:', len(yList))\n",
    "print('Size of training set:', len(yTrain))\n",
    "print('Size of validation set:', len(yValid))\n",
    "print('Size of test set:', len(yTest))\n",
    "\n",
    "# Convert from list to matrix\n",
    "XTrain = XTrainList.reshape((XTrainList.shape[0], XTrainList.shape[1], nFeatures))\n",
    "XValid = XValidList.reshape((XValidList.shape[0], XValidList.shape[1], nFeatures))\n",
    "XTest = XTestList.reshape((XTestList.shape[0], XTestList.shape[1], nFeatures))\n",
    "\n",
    "print(XTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xWe0wFwKPHj"
   },
   "source": [
    "# Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RlsoALJ2KPHr",
    "outputId": "d9a7c7af-bf0a-428b-a2a1-12d74400ddc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37.17359172450686\n",
      "Updating best MAPE to 37.17359172450686...\n",
      "Updating best seed to 0...\n",
      "1 26.307712213280965\n",
      "Updating best MAPE to 26.307712213280965...\n",
      "Updating best seed to 1...\n",
      "2 nan\n",
      "3 394.960185566878\n",
      "4 95.52505157992822\n",
      "5 99.42048238048969\n",
      "6 44.551249459660916\n",
      "7 1103.5888383069937\n",
      "8 nan\n",
      "9 858.3209670164347\n",
      "10 1051.344310141821\n",
      "11 96.71199915249665\n",
      "12 931.7390571017445\n",
      "13 nan\n",
      "14 96.10838464883767\n",
      "15 97.73109928169013\n",
      "16 9008.67591405992\n",
      "17 711.9393393339012\n",
      "18 1513.9125996048558\n"
     ]
    }
   ],
   "source": [
    "nNeurons = 100\n",
    "nFeatures = 1\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "    yPred = list(model.predict(XValid, verbose=0))\n",
    "    yPredList = []\n",
    "    for i in range(len(yPred)):\n",
    "        yPredList.append(yPred[i][0])\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "yPred = list(model.predict(XTest, verbose=0))\n",
    "yPredList = []\n",
    "for i in range(len(yPred)):\n",
    "    yPredList.append(yPred[i][0])\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
    "print('Test MdSA:', MdSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2k4VGyPqKPI0"
   },
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4TYCXnESKPI6",
    "outputId": "e976ebd2-1151-402d-ca72-cfb6789d29de"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(LSTM(nNeurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "    yPred = list(model.predict(XValid, verbose=0))\n",
    "    yPredList = []\n",
    "    for i in range(len(yPred)):\n",
    "        yPredList.append(yPred[i][0])\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(LSTM(nNeurons, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "yPred = list(model.predict(XTest, verbose=0))\n",
    "yPredList = []\n",
    "for i in range(len(yPred)):\n",
    "    yPredList.append(yPred[i][0])\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
    "print('Test MdSA:', MdSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTC8l1MmKPJZ"
   },
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nf8G0jQVKPJh",
    "outputId": "26c5ddba-59de-4cec-ab02-d527b2b7d342"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "    yPred = list(model.predict(XValid, verbose=0))\n",
    "    yPredList = []\n",
    "    for i in range(len(yPred)):\n",
    "        yPredList.append(yPred[i][0])\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(XTrain, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "yPred = list(model.predict(XTest, verbose=0))\n",
    "yPredList = []\n",
    "for i in range(len(yPred)):\n",
    "    yPredList.append(yPred[i][0])\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
    "print('Test MdSA:', MdSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCGbnYIOKPJ6"
   },
   "source": [
    "# CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "uwEt1nAlKPKC",
    "outputId": "afe0a115-e72b-4e01-850d-75195c200ef3"
   },
   "outputs": [],
   "source": [
    "# Number of subsequences to break X into (we do 15 = 5x3, 5 subsequences of size 3 each)\n",
    "nSeq = 5\n",
    "nSteps = 3\n",
    "\n",
    "# define model\n",
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "nFilters = 64\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "\n",
    "# Reshape input\n",
    "XTrainCNN = XTrainList.reshape((XTrainList.shape[0], nSeq, nSteps, nFeatures))\n",
    "XValidCNN = XValidList.reshape((XValidList.shape[0], nSeq, nSteps, nFeatures))\n",
    "XTestCNN = XTestList.reshape((XTestList.shape[0], nSeq, nSteps, nFeatures))\n",
    "\n",
    "# print(XTrainCNN.shape)\n",
    "# print(XValidCNN.shape)\n",
    "# print(XTestCNN.shape)\n",
    "\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(nNeurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrainCNN, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "    yPred = list(model.predict(XValidCNN, verbose=0))\n",
    "    yPredList = []\n",
    "    for i in range(len(yPred)):\n",
    "        yPredList.append(yPred[i][0])\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(nNeurons, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "# fit model\n",
    "model.fit(XTrainCNN, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "yPred = list(model.predict(XTestCNN, verbose=0))\n",
    "yPredList = []\n",
    "for i in range(len(yPred)):\n",
    "    yPredList.append(yPred[i][0])\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
    "print('Test MdSA:', MdSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oRgHaFTKPKZ"
   },
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dd8T6SECKPKh"
   },
   "outputs": [],
   "source": [
    "# Number of subsequences to break X into (we do 15 = 5x3, 5 subsequences of size 3 each)\n",
    "nSeq = 5\n",
    "nSteps = 3\n",
    "# Each input is rows x columns, we have rows=1 and columns=nSteps\n",
    "\n",
    "# define model\n",
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "nFilters = 64\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "\n",
    "# Reshape input\n",
    "XTrainConv = XTrainList.reshape((XTrainList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
    "XValidConv = XValidList.reshape((XValidList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
    "XTestConv = XTestList.reshape((XTestList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
    "\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrainConv, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "    yPred = list(model.predict(XValidConv, verbose=0))\n",
    "    yPredList = []\n",
    "    for i in range(len(yPred)):\n",
    "        yPredList.append(yPred[i][0])\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError(yValid, yPredList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "# fit model\n",
    "model.fit(XTrainConv, yTrain, epochs=1000, verbose=0)\n",
    "\n",
    "yPred = list(model.predict(XTestConv, verbose=0))\n",
    "yPredList = []\n",
    "for i in range(len(yPred)):\n",
    "    yPredList.append(yPred[i][0])\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError(yTest, yPredList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy(yTest, yPredList)\n",
    "print('Test MdSA:', MdSA)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM_time-series-global_nDays15.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
