{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSTM_time-series-global_nDays10_k-day5.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmN6OUIYC1Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# This is not recommended but I am doing this to suppress warnings from SARIMAX\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "countryName = 'Iran'\n",
        "\n",
        "nFeatures = 1\n",
        "\n",
        "nDaysMin = 10\n",
        "k = 5\n",
        "\n",
        "nValid = 10\n",
        "nTest = 10\n",
        "\n",
        "dataDir = os.path.join('data', 'JHU', 'upto07082020_forPublication')\n",
        "\n",
        "\n",
        "# confirmedFilename = 'time_series_covid19_confirmed_global.csv'\n",
        "# deathsFilename = 'time_series_covid19_deaths_global.csv'\n",
        "# recoveredFilename = 'time_series_covid19_recovered_global.csv'\n",
        "\n",
        "confirmedFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_confirmed_global.csv'\n",
        "deathsFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_deaths_global.csv'\n",
        "recoveredFilename = 'https://raw.githubusercontent.com/arkobarman/covid-19_timeSeriesAnalysis/master/data/JHU/upto07082020_forPublication/time_series_covid19_recovered_global.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m08QepwQC1Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps, k):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the sequence\n",
        "        if end_ix + k >= len(sequence):\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+k]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J99kf84C1QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def meanAbsolutePercentageError(yTrueList, yPredList):\n",
        "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    absPcErrorList = [absError/yTrue for absError, yTrue in zip(absErrorList, yTrueList)]\n",
        "    MAPE = 100*np.mean(absPcErrorList)\n",
        "    return MAPE\n",
        "\n",
        "def meanAbsolutePercentageError_kDay(yTrueListList, yPredListList):\n",
        "    # Store true and predictions for day 1 in a list, day 2 in a list and so on\n",
        "    # Keep each list of these lists in a respective dict with key as day #\n",
        "    yTrueForDayK = {}\n",
        "    yPredForDayK = {}\n",
        "    for i in range(len(yTrueListList[0])):\n",
        "        yTrueForDayK[i] = []\n",
        "        yPredForDayK[i] = []\n",
        "    for yTrueList, yPredList in zip(yTrueListList, yPredListList):\n",
        "        for i in range(len(yTrueList)):\n",
        "            yTrueForDayK[i].append(yTrueList[i])\n",
        "            yPredForDayK[i].append(yPredList[i])\n",
        "            \n",
        "    # Get MAPE for each day in a list\n",
        "    MAPEList = []\n",
        "    for i in yTrueForDayK.keys():\n",
        "        MAPEList.append(meanAbsolutePercentageError(yTrueForDayK[i], yPredForDayK[i]))\n",
        "    return np.mean(MAPEList)\n",
        "\n",
        "def meanForecastError(yTrueList, yPredList):\n",
        "    forecastErrors = [yTrue - yPred for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    MFE = np.mean(forecastErrors)\n",
        "    return MFE\n",
        "\n",
        "def meanAbsoluteError(yTrueList, yPredList):\n",
        "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    return np.mean(absErrorList)\n",
        "\n",
        "def meanSquaredError(yTrueList, yPredList):\n",
        "    sqErrorList = [np.square(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    return np.mean(sqErrorList)\n",
        "\n",
        "def rootMeanSquaredError(yTrueList, yPredList):\n",
        "    return np.sqrt(meanSquaredError(yTrueList, yPredList))\n",
        "\n",
        "def medianSymmetricAccuracy(yTrueList, yPredList):\n",
        "    '''https://helda.helsinki.fi//bitstream/handle/10138/312261/2017SW001669.pdf?sequence=1'''\n",
        "    logAccRatioList = [np.abs(np.log(yPred/yTrue)) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
        "    MdSA = 100*(np.exp(np.median(logAccRatioList))-1)\n",
        "    return MdSA\n",
        "\n",
        "def medianSymmetricAccuracy_kDay(yTrueListList, yPredListList):\n",
        "    # Store true and predictions for day 1 in a list, day 2 in a list and so on\n",
        "    # Keep each list of these lists in a respective dict with key as day #\n",
        "    yTrueForDayK = {}\n",
        "    yPredForDayK = {}\n",
        "    for i in range(len(yTrueListList[0])):\n",
        "        yTrueForDayK[i] = []\n",
        "        yPredForDayK[i] = []\n",
        "    for yTrueList, yPredList in zip(yTrueListList, yPredListList):\n",
        "        for i in range(len(yTrueList)):\n",
        "            yTrueForDayK[i].append(yTrueList[i])\n",
        "            yPredForDayK[i].append(yPredList[i])\n",
        "    # Get MdSA for each day in a list\n",
        "    MdSAList = []\n",
        "    for i in yTrueForDayK.keys():\n",
        "        MdSAList.append(medianSymmetricAccuracy(yTrueForDayK[i], yPredForDayK[i]))\n",
        "    return(np.mean(MdSAList))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "972JEm69C1Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get all three frames for a given country\n",
        "def getCountryCovidFrDict(countryName):\n",
        "    countryCovidFrDict = {}\n",
        "    for key in covidFrDict.keys():\n",
        "        dataFr = covidFrDict[key]\n",
        "        countryCovidFrDict[key] = dataFr[dataFr['Country/Region'] == countryName]\n",
        "    return countryCovidFrDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRE7g5bLC1RK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1a327992-7a27-49e3-9719-2d2fdcc2fd51"
      },
      "source": [
        "# Load all 3 csv files\n",
        "covidFrDict = {}\n",
        "# covidFrDict['confirmed'] = pd.read_csv(os.path.join(dataDir, confirmedFilename))\n",
        "# covidFrDict['deaths'] = pd.read_csv(os.path.join(dataDir, deathsFilename))\n",
        "covidFrDict['confirmed'] = pd.read_csv(confirmedFilename)\n",
        "covidFrDict['deaths'] = pd.read_csv(deathsFilename)\n",
        "\n",
        "# Recovered is back again!\n",
        "covidFrDict['recovered'] = pd.read_csv(recoveredFilename)\n",
        "\n",
        "countryCovidFrDict = getCountryCovidFrDict(countryName)\n",
        "\n",
        "# Get list of dates\n",
        "colNamesList = list(countryCovidFrDict['confirmed'])\n",
        "dateList = [colName for colName in colNamesList if '/20' in colName]\n",
        "dataList = [countryCovidFrDict['confirmed'][date].iloc[0] for date in dateList]\n",
        "dataDict = dict(zip(dateList, dataList))\n",
        "\n",
        "# Get time series for cases > 100 only\n",
        "daysSince = 100\n",
        "nCasesGreaterDaysSinceList = []\n",
        "datesGreaterDaysSinceList = []\n",
        "\n",
        "for key in dataDict.keys():\n",
        "    if dataDict[key] > daysSince:\n",
        "        datesGreaterDaysSinceList.append(key)\n",
        "        nCasesGreaterDaysSinceList.append(dataDict[key])\n",
        "        \n",
        "XList, yList = split_sequence(nCasesGreaterDaysSinceList, nDaysMin, k)\n",
        "\n",
        "XTrainList = XList[0:len(XList)-(nValid + nTest)]\n",
        "XValidList = XList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
        "XTestList = XList[-nTest:]\n",
        "\n",
        "yTrain = yList[0:len(XList)-(nValid + nTest)]\n",
        "yValid = yList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
        "yTest = yList[-nTest:]\n",
        "\n",
        "print('Total size of data points for LSTM:', len(yList))\n",
        "print('Size of training set:', len(yTrain))\n",
        "print('Size of validation set:', len(yValid))\n",
        "print('Size of test set:', len(yTest))\n",
        "\n",
        "# Convert from list to matrix\n",
        "XTrain = XTrainList.reshape((XTrainList.shape[0], XTrainList.shape[1], nFeatures))\n",
        "XValid = XValidList.reshape((XValidList.shape[0], XValidList.shape[1], nFeatures))\n",
        "XTest = XTestList.reshape((XTestList.shape[0], XTestList.shape[1], nFeatures))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total size of data points for LSTM: 119\n",
            "Size of training set: 99\n",
            "Size of validation set: 10\n",
            "Size of test set: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtDW0_BtC1Rw",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYZU97YdC1R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import Sequential\n",
        "# from tensorflow.keras.layers import LSTM, Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# nNeurons = 100\n",
        "# # define model\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
        "# model.add(Dense(1))\n",
        "# opt = Adam(learning_rate=0.1)\n",
        "# model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# XTestNew = XTest.copy()\n",
        "# for day in range(k):\n",
        "#     print('Day:', day)\n",
        "#     yPred = model.predict(XTestNew, verbose=0)\n",
        "#     for i in range(len(yPred)):\n",
        "#         yPredListList[i].append(yPred[i][0])\n",
        "#     print('Prediction:', yPred)\n",
        "#     XTestNew = np.delete(XTestNew, 0, axis=1)\n",
        "#     yPred = np.expand_dims(yPred, 2)\n",
        "#     XTestNew = np.append(XTestNew, yPred, axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X1_Sc-NC1SV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be04e702-b1da-43d3-c8bb-13dfadf8cc2e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "nNeurons = 100\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    \n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "    yPredListList = []\n",
        "    for day in range(nTest):\n",
        "        yPredListList.append([])\n",
        "    XValidNew = XValid.copy()\n",
        "    for day in range(k):\n",
        "        yPred = model.predict(XValidNew, verbose=0)\n",
        "        for i in range(len(yPred)):\n",
        "            yPredListList[i].append(yPred[i][0])\n",
        "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
        "        yPred = np.expand_dims(yPred, 2)\n",
        "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "yPredListList = []\n",
        "for day in range(nTest):\n",
        "    yPredListList.append([])\n",
        "XTestNew = XTest.copy()\n",
        "for day in range(k):\n",
        "    yPred = model.predict(XTestNew, verbose=0)\n",
        "    for i in range(len(yPred)):\n",
        "        yPredListList[i].append(yPred[i][0])\n",
        "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
        "    yPred = np.expand_dims(yPred, 2)\n",
        "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.34322677140874197\n",
            "Updating best MAPE to 0.34322677140874197...\n",
            "Updating best seed to 0...\n",
            "1 0.4589418276150516\n",
            "2 1.5027870640675707\n",
            "3 0.17632665925309055\n",
            "Updating best MAPE to 0.17632665925309055...\n",
            "Updating best seed to 3...\n",
            "4 1.2640646925726986\n",
            "5 0.3985663840474194\n",
            "6 99.81090061740807\n",
            "7 1.0321456614773403\n",
            "8 99.8142774504787\n",
            "9 0.2871240991904707\n",
            "10 0.2696088884690415\n",
            "11 2.4376908965283786\n",
            "12 5.398040289717896\n",
            "13 2.000259232609225\n",
            "14 3.14557857249923\n",
            "15 0.8345929432717922\n",
            "16 0.695674469091329\n",
            "17 1.781598786410029\n",
            "18 6624.270749539508\n",
            "19 1.7116669511209992\n",
            "20 1.9509506706652648\n",
            "21 0.5385121123580957\n",
            "22 99.80980616032383\n",
            "23 99.80841740049325\n",
            "24 1.0144854289518752\n",
            "25 1.212335655894605\n",
            "26 12.25479214309216\n",
            "27 0.4184638846276538\n",
            "28 99.84880583332452\n",
            "29 1.2136423406421621\n",
            "30 7.314297689396492\n",
            "31 2.218674116662961\n",
            "32 2.365477252705167\n",
            "33 1.139092340338291\n",
            "34 0.9165957695439134\n",
            "35 99.81678134837023\n",
            "36 99.87770480631613\n",
            "37 1.281654257113844\n",
            "38 99.80956536716776\n",
            "39 99.8375958141225\n",
            "40 1.9159844151654482\n",
            "41 9.247113740440335\n",
            "42 178.78267174665353\n",
            "43 1.9760223146778813\n",
            "44 5.54052356132281\n",
            "45 1.773466177233135\n",
            "46 0.35567775509684807\n",
            "47 99.8110811672839\n",
            "48 0.2330083816938798\n",
            "49 99.80962851988201\n",
            "50 99.81080738054636\n",
            "51 0.5044960107071945\n",
            "52 7.780258320225514\n",
            "53 93.74553348141066\n",
            "54 5.137219680129265\n",
            "55 0.5907600141803562\n",
            "56 99.8550380059172\n",
            "57 6.312655846633912\n",
            "58 99.81187767733076\n",
            "59 99.80900672584588\n",
            "60 0.7184305743992059\n",
            "61 99.86415881155497\n",
            "62 3.9818857675035004\n",
            "63 99.86828935299914\n",
            "64 1.4697290972677384\n",
            "65 1.5742505216004883\n",
            "66 99.80996308979475\n",
            "67 0.659498854317407\n",
            "68 1.4493005567872899\n",
            "69 1.8523844358022856\n",
            "70 99.84058092339913\n",
            "71 1.69392660638947\n",
            "72 5.366781586313094\n",
            "73 1.6291074656812277\n",
            "74 2.359628446325104\n",
            "75 0.8970045597579027\n",
            "76 99.82760894196936\n",
            "77 4.743859601635049\n",
            "78 0.34027388566161265\n",
            "79 99.81572144456399\n",
            "80 99.80950254438929\n",
            "81 3.906951366902528\n",
            "82 2.4643637797845317\n",
            "83 1.5130975918437155\n",
            "84 99.87180424921095\n",
            "85 1.9832439223095952\n",
            "86 2.91366057933184\n",
            "87 0.8714954984020267\n",
            "88 2.0795544123591947\n",
            "89 99.8083853067368\n",
            "90 0.8695160115343427\n",
            "91 0.6775354383721398\n",
            "92 99.84479552349049\n",
            "93 7.474762770135828\n",
            "94 0.18726911513019565\n",
            "95 1.955684323278795\n",
            "96 3.1436678638056437\n",
            "97 99.91153884673939\n",
            "98 2.1462913638561143\n",
            "99 99.84346153300513\n",
            "Training model with best seed...\n",
            "Test MAPE: 1.0463171356355383\n",
            "Test MdSA: 1.0587279215471979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p41QoeWYC1TJ",
        "colab_type": "text"
      },
      "source": [
        "# Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzQNH2GCC1TW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bed9dc6c-ba34-42e5-afd4-e9076e34208b"
      },
      "source": [
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(LSTM(nNeurons, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "    yPredListList = []\n",
        "    for day in range(nTest):\n",
        "        yPredListList.append([])\n",
        "    XValidNew = XValid.copy()\n",
        "    for day in range(k):\n",
        "        yPred = model.predict(XValidNew, verbose=0)\n",
        "        for i in range(len(yPred)):\n",
        "            yPredListList[i].append(yPred[i][0])\n",
        "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
        "        yPred = np.expand_dims(yPred, 2)\n",
        "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(LSTM(nNeurons, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "yPredListList = []\n",
        "for day in range(nTest):\n",
        "    yPredListList.append([])\n",
        "XTestNew = XTest.copy()\n",
        "for day in range(k):\n",
        "    yPred = model.predict(XTestNew, verbose=0)\n",
        "    for i in range(len(yPred)):\n",
        "        yPredListList[i].append(yPred[i][0])\n",
        "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
        "    yPred = np.expand_dims(yPred, 2)\n",
        "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 99.85139428476698\n",
            "Updating best MAPE to 99.85139428476698...\n",
            "Updating best seed to 0...\n",
            "1 51.509603565357565\n",
            "Updating best MAPE to 51.509603565357565...\n",
            "Updating best seed to 1...\n",
            "2 1.0153057627963364\n",
            "Updating best MAPE to 1.0153057627963364...\n",
            "Updating best seed to 2...\n",
            "3 99.86591523985928\n",
            "4 60.67049532478792\n",
            "5 99.57323889748042\n",
            "6 56.17499100053618\n",
            "7 99.83502400944158\n",
            "8 99.891797497223\n",
            "9 99.86682331320263\n",
            "10 3.2981980819772665\n",
            "11 99.82820080182888\n",
            "12 57.831033633878135\n",
            "13 57.29227892325993\n",
            "14 99.83008989432469\n",
            "15 262.92101755424244\n",
            "16 3.6375065109140925\n",
            "17 70.518115569677\n",
            "18 0.9229522933998169\n",
            "Updating best MAPE to 0.9229522933998169...\n",
            "Updating best seed to 18...\n",
            "19 1.8420761924762992\n",
            "20 99.80831066625737\n",
            "21 54.19158677214345\n",
            "22 102.00483611741204\n",
            "23 99.8921323670774\n",
            "24 84.17943349078158\n",
            "25 46.69432017095009\n",
            "26 99.84394818833115\n",
            "27 3.905222148259619\n",
            "28 99.80777081627981\n",
            "29 99.91778588893933\n",
            "30 55.1749077967976\n",
            "31 0.3311271544469788\n",
            "Updating best MAPE to 0.3311271544469788...\n",
            "Updating best seed to 31...\n",
            "32 6.448162323234333\n",
            "33 1.9581881061059465\n",
            "34 99.86622061045247\n",
            "35 99.94504259516766\n",
            "36 152.69700754323168\n",
            "37 0.614283171949918\n",
            "38 421.2506268417469\n",
            "39 56.68948930999649\n",
            "40 0.31641642782638046\n",
            "Updating best MAPE to 0.31641642782638046...\n",
            "Updating best seed to 40...\n",
            "41 79.25526768178035\n",
            "42 2.204547485953868\n",
            "43 99.9604130337514\n",
            "44 99.98641054740418\n",
            "45 1266.4799851610956\n",
            "46 99.94754403353764\n",
            "47 99.83765230813215\n",
            "48 99.83520569909565\n",
            "49 99.82948369725432\n",
            "50 57.1826605684229\n",
            "51 1.598626628088482\n",
            "52 99.81469984330639\n",
            "53 61.25368171166449\n",
            "54 5.229596411019185\n",
            "55 99.81547576235903\n",
            "56 1.2356978190264827\n",
            "57 57.92995582954677\n",
            "58 47.714559453523584\n",
            "59 0.5726127361610643\n",
            "60 99.81848050281658\n",
            "61 99.93312930652972\n",
            "62 0.3839673856569927\n",
            "63 58.62565536810639\n",
            "64 59.428807559431924\n",
            "65 99.83713613854782\n",
            "66 68.75163361953824\n",
            "67 107.04143825003015\n",
            "68 59.03966890588172\n",
            "69 1.3182104883513488\n",
            "70 59.834601619612\n",
            "71 208.78267919465566\n",
            "72 10.017116125985122\n",
            "73 nan\n",
            "74 49.94266927009891\n",
            "75 99.81670450331964\n",
            "76 2.145048957135398\n",
            "77 99.96071295290508\n",
            "78 41.443500385824734\n",
            "79 1.7996318775557243\n",
            "80 616.2387856887977\n",
            "81 0.9604070069236634\n",
            "82 2.972785958265013\n",
            "83 0.7280232671584544\n",
            "84 99.95758511264536\n",
            "85 99.98729399940035\n",
            "86 3.067401827309509\n",
            "87 64.28879174113183\n",
            "88 64.37859187140775\n",
            "89 99.85878507196269\n",
            "90 99.96105244935941\n",
            "91 99.9361556202904\n",
            "92 3.1605185057715417\n",
            "93 8.6489088353843\n",
            "94 0.7118735523219002\n",
            "95 99.84852786240101\n",
            "96 63.09851961676014\n",
            "97 100.36250527026435\n",
            "98 1.3759133867799125\n",
            "99 49.01507957024258\n",
            "Training model with best seed...\n",
            "Test MAPE: 0.6172160254469053\n",
            "Test MdSA: 0.6189209626839176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CkNYlG3C1T_",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkOBCOlJC1UK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9988cdaa-6814-4e55-cbac-a0ee22087c55"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "    yPredListList = []\n",
        "    for day in range(nTest):\n",
        "        yPredListList.append([])\n",
        "    XValidNew = XValid.copy()\n",
        "    for day in range(k):\n",
        "        yPred = model.predict(XValidNew, verbose=0)\n",
        "        for i in range(len(yPred)):\n",
        "            yPredListList[i].append(yPred[i][0])\n",
        "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
        "        yPred = np.expand_dims(yPred, 2)\n",
        "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "yPredListList = []\n",
        "for day in range(nTest):\n",
        "    yPredListList.append([])\n",
        "XTestNew = XTest.copy()\n",
        "for day in range(k):\n",
        "    yPred = model.predict(XTestNew, verbose=0)\n",
        "    for i in range(len(yPred)):\n",
        "        yPredListList[i].append(yPred[i][0])\n",
        "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
        "    yPred = np.expand_dims(yPred, 2)\n",
        "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 99.91826919241744\n",
            "Updating best MAPE to 99.91826919241744...\n",
            "Updating best seed to 0...\n",
            "1 1.037677485049936\n",
            "Updating best MAPE to 1.037677485049936...\n",
            "Updating best seed to 1...\n",
            "2 4.591244917990075\n",
            "3 1.8928095479630258\n",
            "4 0.8100544783707818\n",
            "Updating best MAPE to 0.8100544783707818...\n",
            "Updating best seed to 4...\n",
            "5 1.3154296225551805\n",
            "6 0.23933080450540425\n",
            "Updating best MAPE to 0.23933080450540425...\n",
            "Updating best seed to 6...\n",
            "7 0.1641875594948325\n",
            "Updating best MAPE to 0.1641875594948325...\n",
            "Updating best seed to 7...\n",
            "8 1.699628156169044\n",
            "9 99.82161126375811\n",
            "10 99.83726443858832\n",
            "11 0.9554948342503818\n",
            "12 0.29317940767326794\n",
            "13 1.0296962473318447\n",
            "14 0.3249975756434636\n",
            "15 1.1230865502115\n",
            "16 0.1631777341051512\n",
            "Updating best MAPE to 0.1631777341051512...\n",
            "Updating best seed to 16...\n",
            "17 99.80981896783227\n",
            "18 4.594299295988977\n",
            "19 99.90584079239007\n",
            "20 3.802510128890893\n",
            "21 1.9354328637567035\n",
            "22 2.57000680146775\n",
            "23 0.20350117682990992\n",
            "24 99.81658964066506\n",
            "25 1.3986897038765214\n",
            "26 7.004385504870203\n",
            "27 99.8581695617041\n",
            "28 8.621787316509511\n",
            "29 4.932624171974121\n",
            "30 2.6613770329679043\n",
            "31 99.88249312729583\n",
            "32 1.8322053875710047\n",
            "33 1.4345178783662733\n",
            "34 0.35301608287857394\n",
            "35 0.7306761010693859\n",
            "36 99.8233447915175\n",
            "37 0.9466419307688106\n",
            "38 2.2303097039100797\n",
            "39 1.2714434482196313\n",
            "40 9465.57770728659\n",
            "41 0.2867990845022324\n",
            "42 6.3861917751676485\n",
            "43 99.81057843508543\n",
            "44 0.2500102852311517\n",
            "45 2.9647863773880054\n",
            "46 1.280269612044516\n",
            "47 4.11635832281724\n",
            "48 1.7648127070680615\n",
            "49 0.8019395293593643\n",
            "50 99.8182105553322\n",
            "51 2.1940679498000306\n",
            "52 99.81474066536485\n",
            "53 0.34303615261731313\n",
            "54 86.86533040489515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iQK7BwrC1Uj",
        "colab_type": "text"
      },
      "source": [
        "# CNN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHguzR7QC1Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import Sequential\n",
        "# from tensorflow.keras.layers import LSTM, Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.layers import Flatten\n",
        "# from tensorflow.compat.v1.keras.layers import TimeDistributed\n",
        "# from tensorflow.keras.layers import Conv1D\n",
        "# from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "# nSeq = 5\n",
        "# nSteps = 3\n",
        "# nNeurons = 50\n",
        "# nFeatures = 1\n",
        "# nFilters = 64\n",
        "\n",
        "# XTestListNew = XTestList.copy()\n",
        "# print(XTestListNew.shape)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
        "# model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "# model.add(TimeDistributed(Flatten()))\n",
        "# model.add(LSTM(nNeurons, activation='relu'))\n",
        "# model.add(Dense(1))\n",
        "# opt = Adam(learning_rate=0.1)\n",
        "# model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "# XTestCNN = XTestListNew.reshape((XTestListNew.shape[0], nSeq, nSteps, nFeatures))\n",
        "# yPred = model.predict(XTestCNN, verbose=0)\n",
        "\n",
        "# XTestListNew = np.delete(XTestListNew, 0, axis=1)\n",
        "# XTestListNew = np.append(XTestListNew, yPred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cgxYTJVC1VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.compat.v1.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "# Number of subsequences to break X into (we do 15 = 5x3, 5 subsequences of size 3 each)\n",
        "nSeq = 5\n",
        "nSteps = 2\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "nFilters = 64\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "\n",
        "# Reshape input\n",
        "XTrainCNN = XTrainList.reshape((XTrainList.shape[0], nSeq, nSteps, nFeatures))\n",
        "\n",
        "# print(XTrainCNN.shape)\n",
        "# print(XValidCNN.shape)\n",
        "# print(XTestCNN.shape)\n",
        "\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
        "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "    model.add(LSTM(nNeurons, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "    # fit model\n",
        "    model.fit(XTrainCNN, yTrain[:,0], epochs=1000, verbose=0)\n",
        "    \n",
        "    yPredListList = []\n",
        "    for day in range(nTest):\n",
        "        yPredListList.append([])\n",
        "    XValidListNew = XValidList.copy()\n",
        "    for day in range(k):\n",
        "        XValidCNN = XValidListNew.reshape((XValidListNew.shape[0], nSeq, nSteps, nFeatures))\n",
        "        yPred = model.predict(XValidCNN, verbose=0)\n",
        "        for i in range(len(yPred)):\n",
        "            yPredListList[i].append(yPred[i][0])\n",
        "        XValidListNew = np.delete(XValidListNew, 0, axis=1)\n",
        "        XValidListNew = np.append(XValidListNew, yPred, axis=1)\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=nFilters, kernel_size=1, activation='relu'), input_shape=(None, nSteps, nFeatures)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(nNeurons, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "# fit model\n",
        "model.fit(XTrainCNN, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "yPredListList = []\n",
        "for day in range(nTest):\n",
        "    yPredListList.append([])\n",
        "XTestListNew = XTestList.copy()\n",
        "for day in range(k):\n",
        "    XTestCNN = XTestListNew.reshape((XTestListNew.shape[0], nSeq, nSteps, nFeatures))\n",
        "    yPred = model.predict(XTestCNN, verbose=0)\n",
        "    for i in range(len(yPred)):\n",
        "        yPredListList[i].append(yPred[i][0])\n",
        "    XTestListNew = np.delete(XTestListNew, 0, axis=1)\n",
        "    XTestListNew = np.append(XTestListNew, yPred, axis=1)\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5waknOSC1VS",
        "colab_type": "text"
      },
      "source": [
        "# ConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlz7DGTNC1VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import ConvLSTM2D\n",
        "\n",
        "# Number of subsequences to break X into (we do 15 = 5x3, 5 subsequences of size 3 each)\n",
        "nSeq = 5\n",
        "nSteps = 2\n",
        "# Each input is rows x columns, we have rows=1 and columns=nSteps\n",
        "\n",
        "# define model\n",
        "nNeurons = 50\n",
        "nFeatures = 1\n",
        "nFilters = 64\n",
        "\n",
        "bestValidMAPE = 100\n",
        "bestSeed = -1\n",
        "\n",
        "# Reshape input\n",
        "XTrainConv = XTrainList.reshape((XTrainList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "# XValidConv = XValidList.reshape((XValidList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "# XTestConv = XTestList.reshape((XTestList.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "\n",
        "for seed in range(100):\n",
        "    tf.random.set_seed(seed=seed)\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    opt = Adam(learning_rate=0.1)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "    \n",
        "    # fit model\n",
        "    model.fit(XTrainConv, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "    yPredListList = []\n",
        "    for day in range(nTest):\n",
        "        yPredListList.append([])\n",
        "    XValidListNew = XValidList.copy()\n",
        "    for day in range(k):\n",
        "        XValidConv = XValidListNew.reshape((XValidListNew.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "        yPred = model.predict(XValidConv, verbose=0)\n",
        "        for i in range(len(yPred)):\n",
        "            yPredListList[i].append(yPred[i][0])\n",
        "        XValidListNew = np.delete(XValidListNew, 0, axis=1)\n",
        "        XValidListNew = np.append(XValidListNew, yPred, axis=1)\n",
        "\n",
        "#     for yTrue, yPred in zip(yTest, yPredList):\n",
        "#         print(yTrue, yPred)\n",
        "\n",
        "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
        "    print(seed, MAPE)\n",
        "    if MAPE < bestValidMAPE:\n",
        "        print('Updating best MAPE to {}...'.format(MAPE))\n",
        "        bestValidMAPE = MAPE\n",
        "        print('Updating best seed to {}...'.format(seed))\n",
        "        bestSeed = seed\n",
        "\n",
        "# define model\n",
        "print('Training model with best seed...')\n",
        "tf.random.set_seed(seed=bestSeed)\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(nSeq, 1, nSteps, nFeatures)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "opt = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "# fit model\n",
        "model.fit(XTrainConv, yTrain[:,0], epochs=1000, verbose=0)\n",
        "\n",
        "yPredListList = []\n",
        "for day in range(nTest):\n",
        "    yPredListList.append([])\n",
        "XTestListNew = XTestList.copy()\n",
        "for day in range(k):\n",
        "    XTestConv = XTestListNew.reshape((XTestListNew.shape[0], nSeq, 1, nSteps, nFeatures))\n",
        "    yPred = model.predict(XTestConv, verbose=0)\n",
        "    for i in range(len(yPred)):\n",
        "        yPredListList[i].append(yPred[i][0])\n",
        "    XTestListNew = np.delete(XTestListNew, 0, axis=1)\n",
        "    XTestListNew = np.append(XTestListNew, yPred, axis=1)\n",
        "    \n",
        "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
        "print('Test MAPE:', MAPE)\n",
        "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
        "print('Test MdSA:', MdSA)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}